20180530-AWS_Summit_Tokyo_2018.md
-----

### 概要

* AWS Summit Tokyo 2018
* 2018年5月30日（水）〜 6月1日（金）
* 会場：　グランドプリンスホテル新高輪（国際館パミール、飛天）
* 主催：　アマゾン ウェブ サービス ジャパン株式会社
* https://www.awssummit.tokyo/tokyo/
* Twitter : [#AWSSummit](https://twitter.com/search?q=%23awssummit) 、 [アマゾン ウェブ サービス公式アカウント](https://twitter.com/awscloud_jp)

-----

### Amazon Connect で始めるクラウド型コンタクトセンター

* 5月30日(水) 14:00-14:40 飛天 1-H1-2-14

#### 木村 雅史 アマゾン ウェブ サービス ジャパン株式会社 技術統括本部 ソリューションアーキテクト

* Amazonコンタクトセンターは7万人
* これまでライセンスはセールス時の最大値を見越して買うしかない
* 平常時との差が大きく費用が重荷になっていた → なので自分で作った
* コールセンター設置に3ヶ月かかるのが数時間で構築可能に
* 例えば発信元電話番号をCRM参照し顧客状態を把握した上で会話可能に
* 通話録音をS3にメトリクスをDWHへ保存できる
* Salesforceのプラグインとして利用可能、過去のサービス履歴を確認した上ワンクリックで発信可能(間違い電話が無い)
* 顧客接続時間に応じた従量課金、電話回線費用込み、オートスケール
* (日本における料金一例)0080番号は$0.48/日、着信通話料は$0.2294/分、発信通話料は$0.1383/分
* デモ「エーダブリューエスホテル予約センター」を4分で制作

#### 谷澤 雄一郎 株式会社AOKI suitsbox事業部 システム開発・UX担当

* 新規事業で(特に事前)予算が無かったのでAmazon Connectはぴったりだった
* 通話自動応答フロー制作は2日
* SalesforceにAria Solutions Toolkitを追加し、着信時自動ポップアップ・注文後のメモが可能に
* Magento + Stripe + Salesforce + Amazon Connectでリーンスタートアップ、人間はサービス部分だけに注力
* 実は4月の段階では発信番号が非通知だったけど要望出したらすぐに改善された
* 新事業で手に入れたAmazon ConnectのノウハウをAOKI本体に展開、単独のビジネス以上の利益が

#### 事例：株式会社イープラス

* (お年寄り向けの)チケットの抽選販売の当落の電話をオペレータ応答にしているが非常に費用がかかる
* Amazon Connectで自動応答にしたら、オペレータ0人にして24時間応答可能に

#### デモ

* Amazone Dashボタンを押すと電話発信
* データセンターの死活監視にも使える

-----

### 【任天堂様ご登壇事例】Nintendo Switch （TM） 向けプッシュ通知システム「NPNS」

* 5月30日(水) 16:00-16:40 香雲 1-P3-1-16
* 記事化NGセッションなのでタイトルのみ

-----

### 【AWS Tech 再演】AWS のネットワーク設計入門

* 5月30日(水) 19:00-19:40 飛天 1-H1-2-19
* 益子 直樹 アマゾン ウェブ サービス ジャパン株式会社 技術統括本部 ソリューションアーキテクト

#### VPC内から外サービスへのアクセスGW

* Inernet Gateway → 単純にインターネットへ繋ぐ、双方向に広範囲に接続したい場合は良いがセキュリティ的にはやや弱い
* NAT GatewayはAZ毎に設置推奨 → 内側から外側だけ広範囲なアクセスができる
* VPC Endpoint Gateway Type → S3やDBに接続できる
* VPC Endpoint Interface Type → 新しいサービスで接続先がどんどん増えている
* Time Sync →  ただのNTPだけど、NTPのためだけに設定したGateway除去できる

#### マルチAZ

* RDSにマルチAZを指定するとMasterの死活監視をしてSlaveが自動的に昇格する

#### VPCのアドレス

* 一つ目のVPCは変更・削除不可能なので慎重にアドレスを決める
* 基本的には/16(VPCの最大値)で取れば良い
* プライベートアドレスの空きが無い場合、RFC6598 100.64.0.0/10を使うと良い
* VPC Peering(2Hopは不可能で)2つのVPCを接続する
* Direct Connect Gateway、VPCアドレスが別々のものを接続する

-----

### おまけ：オフィス向け無人コンビニ600

* 飛天 地下1階 特設ブース
* https://www.nikkei.com/article/DGXMZO30971150V20C18A5000000/
* RFIDが容器からはみ出して貼られているのはタグの電波はアルミ包装や水を通さないので
* 現状、商品の価格はコンビニに合わせてあるけど、1施設1台設置だと配送コストを考えたら物が売れる毎に若干運営会社の赤字
* 設置費用一月一台5万円から上記赤字分を引いたのが運営会社の利益(なので複数纏めて設置してもらえると配送コストが減って嬉しい)
* 直近のターゲットは福利厚生等で費用会社持ちでもコンビニを置きたいが人件費が捻出出来ない(もしくは単純に雇う人が居ない)所
* 支払いがクレジットカードのみなのが難点、交通系ICカードにも対応したいが料金の徴収方法が難しい(二度タッチ？カード入れてロックする？)

-----

### クラウドへのデータウェアハウスマイグレーション手法

* 5月31日(木) 13:00-13:40 飛天 2-H1-3-13
* 下佐粉 昭 アマゾン ウェブ サービス ジャパン株式会社 技術統括本部 ソリューションアーキテクト

#### 本編
* (入場が遅れたので7分目から)
* 最近は汎用RDBMSの性能が上がっており、専用のデータウェアハウスソフトを使わなくても処理できる場合がある
* データウェアハウスは一括書き込み・SQLの並列読み込み等が優れている
* 事前検証：卓上計算・機能確認に期間を費やしすぎない、仮説を立てたらレッドシフトで試すと良い(費用は1時間単位)
* 機能確認のポイント(スライドで使った表)は後にPDFでアップする
* セキュリティはビルドインのものを使った方が安く早くできるかと
* アプリケーション見直しの検討をする：既存で(ハードを使い切るため)多数データウェアハウス叩くアプリがあっても、移植先はRedshiftだけでなくAurora等より適した物があるか検討する
* (例)大半のユーザが一部のデータしか使わないなら、それだけAuroraに切り出してRedshiftは特権ユーザだけにしてコストを下げる
* 一度に全アプリを移植するのではなく、修正が小さい物から順に移植すると良い

#### 性能検証

* リザルトキャッシュを必ず無効化にする
* ディスクI/O・ネットワーク・実行待ちに対応する
* ディスクI/O：均一に分散する・並列数を増やす、ソートキー設定は重要、またログでソートキーが有効だったか確認できる
* ネットワーク：DS_DIST*→この???が出たら遅いよ、分散方式EVEN・DISTKEY・ALL、性能をよく使うSQLに合わせるか重要度に費用が間に合うなら表をコピーすると良い
* 実行の制御：キューは5個(メモリを均等に分割するため)、一時的に利用スロットを上げるコマンドもある(バッチ等に)
* ショートクエリーアクセラレーション(短いと思ったコマンドを専用キューで実施し待たせない)、逆に長い処理をバッチ用キューに移動して短い処理向けにキューを空ける
* 時間によってメモリ配分を変える(例：夜間は閲覧用のメモリ割り当てを削減しバッチ処理用に宛てる)

#### 移行

* 移行の量を計画する、資産の重要度を検証し全部移行しようとしない

-----

### Amazon Redshift の設計・運用大原則

* 5月31日(木) 14:00-14:40 飛天 2-H1-3-14
* 仲谷 岳志 アマゾン ウェブ サービス ジャパン株式会社 プロフェッショナルサービス シニア・インフラストラクチャー・アーキテクト

#### 本編

* RedshiftはDWHである以上得意不得意なworkロードがある、良さを引き出す設計が必要
* 1・サイジングをちゃんとする：キャパシティ変更には時間がかかるので変更回数を減らす(EC2と比べると)、データ容量は7割で拡張を目安にする(3割は一時テーブルとして使う(初期は8割利用でアラートだが下げる)、1年後に7割以下になりそうなキャパシティを選択)、可能な場合は大きめのノードサイズを選択する(リーダーノードはコンピュートノードに比例する)
* 2・Spectrumのアーキ原則を抑える：データ量に応じたノードスライス数を用意する、古いデータはS3に追い出して繋ぐとコスト節約になる、システムクエリや失敗したクエリには課金されない
* 3・COPYの基本ルール：可能な場合は常にS3からロードする(EC2は遅くて不安定)、一時制約違反の行がロードされるのは仕様(性能重視でロード時は止めない、必要なら一時テーブル使う)、夜間バッチでは許容ロードエラー数を上げる(エラーした物のみ後で処理する)
* 4・ロード経路をセキュアにする：Redshiftと同じプライベートVPCにプロキシーEC2を立ててそこからS3にコピーすると良い、AWSコンフィグ等で監視する
* 5・同時実行要件に正しく対処する：スロット細分が以外の方法を考える(メモリはスロットで等分に割るのでスロット数を減らし十分なメモリを容易した方が処理速度上がる場合がある)、定型クエリはデータマート(キャッシュレイヤ)で対応、探索クエリはRedshift Spectrum
* 6・クエリー特性を考慮する：対話クエリーはキューを分け(特に日中は)優先する、クエリーモニタリングルールで予防線を張る、BIツールに備える(結果セットキャッシュが有効(性能即提示はOFFにしよう))
* 7・VACUUMを工夫する：VACUUM FULL(DELETE_ONLYだとデータ容量が減らない場合がある)を短くてもWeeklyにとどめて実行する、頻繁に削除がある場合VACUUMの代わりにディープコピーを使おう
* 8・：UPSERTは一時テーブルを使って行う

-----

### AWS を支えるネットワークインフラと要素技術

* 5月31日(木) 18:00-18:40
* 岡本 京 アマゾン ウェブ サービス ジャパン株式会社 技術統括本部 ソリューションアーキテクト

### 本編

* AWSは世界最大級のオンプレミスサーバ構築を行っている(ある意味当然)
* AWSネットワークの特徴：規模や技術が随時更新される
* ネットワーク大好きやTCP/IP好きな人がこの講演のターゲット
* AZ：数十万台規模のサーバで構成
* リージョン：複数のAZ＋外部ネットワーク接続ようのトランジットセンターで構成、AZ間通信は通常1m秒で通信できる

####  AmazonVPC

* (2006年AWS開始時には無く)2009年に登場
* VLAN、VRFの最大数(数千)にぶつかる
* クラウドスケールの分散型仮想ネットワーク、巨大なSDNといえる(インスタンスと物理マシンを結びつけてカプセル化して送信)
* VPC Peering(ホワイトリスト式なのでセキュリティ的に強固)、VPC Flow Logs(全ての送受信ログを取得し、トラブルシューティングやセキュリティで使える)
* 早期に25GbEにコミットしブロードコムにチップ制作を依頼(100Gの四分の一が25Gbps)
* 最新性能はブログに掲載：(例)2018年1月EC2-S3間通信速度が25Gbpsに増強
* VPCネットワーク利用用の料金例：VPC内部・対S3・Flow Logs取得は無料、AZ間・VPC Peeringは$0.01/1G

#### ロードバランサー

* 従来のハードウェアロードバランサー：実装がブラックボックス、1台に複数サービス搭載するのでキャパシティ管理が困難、アクティブスタンバイなので半分遊ぶ
* S3ロードバランサー：
* AWS Hyperplane：
* Network Load Balancer：毎秒数客万リクエストにも対応、急激なスパイクにも対応、料金例は$17.50/月＋使用量課金

#### リージョン

* 2006-2010年の5年間は4リージョン
* その次の5年で7リージョン開設(計11)、現状18リージョン、計画中含め22
* エッジロケーション：CloudFront・Route53などは世界100カ所で提供、日本はうち8カ所(これをエッジロケーションと呼ぶ)
* 中国を除く全てのリージョンに100GbEプライベートネットワーク(光ファイバー)が接続されている
* Amazonグローバルネットワーク：Amazon社内的にはS3のリージョン間データコピーなどで利用、ユーザ向けにはリージョン間VPC PeeringやDirect Connect Gatewayで使える
* Direct Connect Gateway：最寄りのリージョンに接続するだけで全リージョンへのDirect Connectとして使える(世界中の拠点が国内回線だけでアクセスできる)
* Direct Connectを分割して(通常インターネット越しに触る)S3・IoTもアクセスできる
* Direct Connect料金：1Gbps回線は1ヶ月2万円ほど、オンプレミスへのデータ受信は東京リージョンから東京拠点で約$0.04/G・北米リージョンから東京拠点で約$0.05(国際回線に比べたら非常に安価)

-----

### re:Mix （re:Mix networking mixer in AWS Summit Tokyo）

* 5月31日(木) 19:00-20:30 香雲 2-P3-1-19
* 司会はAWS芸人ソリューションアーキテクト 志水さん https://twitter.com/awscloud_jp/status/1002139254326153217
* ゲスト 池澤あやかさん
* 乾杯の挨拶は AWSサムライ 友岡さん：MS Wordで出張報告書いているのはクソ、外へ向けてブログ書こう！

=====

### 一つ目のコーナー：JAWS-UG紹介

* セキュリティJAWS 大竹さん
* Japan AWS User Groupの略
* 全国に50支部：レジャーランド支部も？？？

#### 初心者支部の紹介

* いしいさん
* 主な開催場所は目黒のAWSJオフィス
* 誰でも参加できるカジュアルな会として開催
* 次回は6月22日目黒で開催、connpassで参加登録して！
* おう すいさん：マーケッティングが得意、私でも出来るのでみんな運営にJoin！
* ふじまきさん：
* 最近の課題：参加者が成長してしまって玄人支部となっている

#### JAWS-UG AI

* AI支部のテーマはAWS上でマシンラーニングを乗せる
* ユーザーグループは「別分野のエキスパート」と交流出来る
* AWSたくさんサービスが増えるのでネタが尽きない！
* AI支部は座学＆ハンズオン！
* 座学の講師には謎のAI企業も？！
* 7月に座学の会開催、参加したい人はググってconnpassのメンバーになって
* より強いフィードバック欲しい人は登壇＆運営になろう！
* 私の運営しているコンテナ支部も登壇＆運営募集中！

#### X-Tech JAWS

* エックステック(X-Tech)はAWSをハブにする、クロステック(XTech)は複数のサービスを直接結びつける
* 登壇者の探し方：面白そうなサービスのDNS登録を調べ、Route53利用＋IPアドレスの先頭が「52.」ならAWSユーザーと見なす！
* JAWS DAYS 2018では専用トラックを設けて発表しました
* 空気を知りたい人はASCIIさんのJAWS-UGレポート読むと良いよ！
* 手書きのロゴから変わります！ ~~X Japan風のロゴ~~ 、Xを光の輪で書いたものに決まりました
* 最近、運営やりたいメンバーを追加募集中です!
* 大竹さん：X-Tech支部の治安維持も募集中です！

##### 次回JAWS FESTAのお知らせ

* 11月3日(土祝)、大阪パナソニックスタジアム吹田で開催
* まもなく応募開始

=====

### 続きましてAmazon Alexa

* Amazon 畠中さん
* 3月からAmazon Echo日本販売しました！
* もっともっとスキルを使ってAlexaを快適に使いましょう！
* 日本語スキル700超えました！
* Alexa Skills Kit：実行環境にLambdaを使えば多くは無料枠でやれるよ！
* 一週間に一回オンラインセミナー「Alexa道場」もやるよ！(Youtube録画放送もあり)、27日18時にこれまでの6回ダイジェスト版やるよ！
* Alexaスキル開発プロモーション！：スキル公開後申し込むと毎月AWS$100がもらえる！、必ず毎月変わるTシャツももらえますよ！ https://twitter.com/awscloud_jp/status/1002140402277728256
* Alexa Dev Days Tokyo 2018：10月12-13日にAWS新社屋目黒セントラルスクエア上層の一番広い部屋で開催！
* 今日発表！ Amazon Alexa スキルアワード2018開催！ https://twitter.com/awscloud_jp/status/1002141447548645376
* MAアワードプロデューサー伴野さんからスキルアワードの紹介：9月29日に審査・表彰式開催、スポンサーのみなさんありがとうございます！
* スキル「イケハヤ」の紹介：適当に色々ひどい台詞(MP3)を言われる

=====

### AWSウルトラクイズ

* グーチョキパーの三択でクイズ、上位3名はAWS re:Inventカンファレンスチケット(去年より値上げして$1799相当)
* 注意事項：検索しない、周りの人を見て回答を変えない、一度間違えたら次の問題参加しない
* 練習問題-開催場所は？：ラスベガス、サンタクララ、シアトル

#### 本番

* 選択肢は頭からグーチョキパー、答えは「」でくくった物
* 1問目EC2は何の略？：Cloud Computing、Computing Cloud、「Comput Cloud」：今回最大の難問でほぼ3分割
* イレブンナインの耐久性を誇るAWSストレージサービスは？：EFS、「S3」、EBS
* 7月東京リージョンへリリースされるAWSストレージサービスは？：「EFS」、S3、EBS
* S3に対して直接SQLを実行できるサービスは？：「Athena」、Kinesis Data Analystic、Aurora
* AWSオンラインセミナーの名前は？：「ブラックベルト Online Seminar」、On-Air、Launch
* Loft Tokyoはどこに出来る？：東京駅、渋谷駅、「目黒駅」
* CodePipelineのソースとして使えるサードパーティーは？：「GitHub Enterprise」、SourceForge、GitLab
* 東京にCloudFrontのエッジロケーションが追加されたか東京で何個目？：7、「8」、9
* 2018年5月16日から始まったアップデート情報を3分で紹介する動画のタイトルは?：「Service Update」、Update 動画、innovation：AWSJ 西谷さんが担当
* Snowball Edgeの重さは？：「22.6kg」、23.8kg、24.2kg
* ここで丁度三人になり終了！

#### 勝利者インタビュー

* 一人目：クラウドパック絶賛エンジニア募集中！
* 志水さん：目録の看板は3枚あるので持ち帰って良いです
* 二人目：じゃんけんの運だけで勝利、今後ともよろしくお願いします
* 三人目：こんなところでこんな話をして緊張している、AWS歴1年半、結構頑張ってJAWS勉強会行っている、re:Inventで自分が得た情報をコミュニティに還元できるように頑張る、そのへんでお会いしましたらよろしくお願いします

=====

### 最後の挨拶

* 集合写真撮影します
* はーい解散、今日はありがとうございました

-----

### 【アカツキ様ご登壇事例】大規模環境における Ruby on Rails on AWS での最適化事例 ～ 200ms → 100ms への歩み ～

* 6月1日(金) 12:00-12:40 旭光 3-P1-2-12
* 長井 昭裕 株式会社アカツキ サーバーサイドエンジニア

#### 本編

* (5分遅れで入場したので途中から)
* サーバレスポンスを早くすればユーザも嬉しいしサーバ資源も軽くすむ(コストが安い)
* 運用して数年したRoR制作のゲームサーバ高速化に挑戦
* サーバのレスポンスタイムの長短は体験に直結
* キャラのデータが大量でイベント数百個のフラグを管理、またゲームロジックが複雑
* 他のWEBアプリに比べDBへの書き込みが多数ある

#### DBの種類

* MasterDB：基本は読み込みのみなのでリードレプリカを大量に容易→8xlarge数台
* UserDB：書き込みが多いので水平分割→8xlarge数十台
* Cache：垂直・水平分割を同時に行う→
* EC2は数十台利用
* デザインパターンで複数AZにインスタンスを設置→そのままだと使うDBの設置AZが読めない(同一AZだと1msec,他AZだと2.5Sec)→基本的に同一AZのDBを使うようにしたが障害発生時の冗長は忘れない→15msec節約した
* RoRのDBコネクション死活監視が重い→リクエストのたびデータ送信の前にpingで疎通確認をしていた→前の監視後30秒はping送らないようにした(Octopusプラグインが原因？)→60msec節約した→この件はspotifyも困って論議中

#### フレンド機能の高速化

* フレンドリストに必要なデータはキャッシュに置く
* レベルアップなどデータ変更時は忘れずにキャッシュ更新する
* 900msecかかっていたものが300msecに短縮された

#### 効果

* アプリケーション最適化で35msec節約→計100msec短縮
* EC2台数を2/3に減らせた→数千万円節約
* リージョン間通信も2/3にできた→数百万円節約
* AWSエンタープライズサポートで詳細のコストレポートもらえるよ
* また資料はあとで公開されます

-----

### 【 f4samurai 様ご登壇事例】『マギアレコード 魔法少女まどか☆マギカ外伝』を支えるインフラ

* 6月1日(金) 14:00-14:40 旭光 3-P1-2-14
* 森田 佳介 株式会社f4samurai テクニカルエンジニア

#### 本編

* 宣伝・ワンダーグラビティー事前登録受付中！
* マギアレコードはf4samuraiが開発運用
* クライアントはメニューWebViewとCocos2s-xで作成(バトルはCocos2s-xのみ)
* マギアレコードが初のAWS利用でエンジニアの教育からスタート(これまではセガのオンプレミスを利用)
* 強力なIPなのでリリース時の負荷が読めない
* AWS選定はAuroraの存在が一番の決め手、調達・スケールアウトの用意さも重要
* 自分が入社してDBの性能検証を始めた
* クライアントからの通信は全てHTTP2で「一般データはAWS通信」の他に「ログはTREASURE DATAへ直接送信」、解析はMackerel
* ユーザーデータは8つのDBへ分割それぞれマスタースレーブがある、また一部データはDynamoDBへ保存
* ユーザのあいまい検索のためLambda＋Elasticserchを構築
* S3に過去ログ全部保存してAthenaで検索
* KPIは先ほどのクライアントからのログにDBのデータとEC2からのログを足し算し、RedShift＋Sepersetで解析(AuroraはDBが分割されているため直接検索が難しい)、日次バッチ処理なので一日遅れのデータしか取れない
* AWSをTerraformで管理、複数の環境を同一コード＋変数ファイルで対応、CloudFormationは一目見て厳しいので段園
* Ansibleを設定管理に利用

#### AWSを使った感想

* サーバエンジニア3名・クライアントエンジニア4名・フロントエンジニア2名
* サーバエンジニアはメインサーバプログラム作成が一人、メインインフラエンジニアも一人、兼任ヘルプが一人
* 開発期間：16年8月プロジェクト(登壇者が)JOIN(この時点ではオンプレで進んでいた)、10月AWS採用決定、17年5月リリース延期、8月リリース
* AWSには「充実したドキュメント・ベストプラクティス・リファレンス」「ソリューションアーキテクトのサポート」「マネージドサービスの活用で工数削減」「ブラックベルトオンラインセミナーで概要を掴んでからドキュメントを読む」

#### 最後に

* 下記の職種で求人募集中！(詳細略)
* サーバエンジニアすごく人数少ないので、採用されればすぐに重要な仕事任されると思います

-----

### 【 gumi 様ご登壇事例】gumi が目指す「 Less DevOps, More Code 」～運用を削減して, もっとコードを書こう！～

* 6月1日(金) 15:00-15:40 旭光 3-P1-2-15
* 幾田 雅仁 株式会社gumi CTO

#### 本編

* 毎年3,4ほどのソシャゲを開発、海外展開もできるだけ自社開発
* エリクサー、nodeJS、Python、PHPで開発
* インフラはAWSを8年使っている
* gumi TECH Drinkupを開催中！ https://gumitech.connpass.com/event/84157/
* 1200監視ポイント・20AWSアカウント・70環境 vs インフラエンジニア5人
* 余力を作ります、その余力で調査実験、教育説得、コード化
* スタートアップから一部上場企業への成長痛の講演
* 一人手作業からチームコード化の歴史
* 実験的であることと失敗から学ぶこと

#### 会社の歴史
* 2010年ヒーロー登場：初代CTOがAWS全面導入、一人に権限と責任を集中させ品質の均質化を実現、
* 2012年チーム結成：初代CTOがAWSへ転職、運用チーム・共通開発チーム結成し共通でツールを開設、得意な人がやると属人化
* 2014年管理統制：依頼がプライベートチャットで飛び交い他の人が知らないタスクが積み上がるのを防止、公開チャットを使う・チケットの徹底・要件毎に担当者を作る、ジョブローテーションで開発者を運用チームに入れ要件定義・コード化を実施、管理者による統制を強めると他のメンバーが承認無しで動けなくなる
* 2017年自己組織化：社内外から数名招聘、前回権限が足りなかったので信頼できる人を増やしてしっかり権限渡す、コードから回るまで手作業する人をアウトソーシングで確保、8ヶ月で転職ドラフトさんを使い2名招聘(＋その後さらに一人)、現場の意見を聞いてもらえる・信頼されて任せてもらえる
* 次回予告旧環境との戦い：早く旧環境を撤去したい、ピタゴラスイッチが完成しており

#### ツール選択の話

* ツール選択：実験的であること、素早く試す、小さく本番に適用する、現場毎の背景を理解(他者の事例をそのまま採用しない)、適材適所で使う
* AWS：とっても良いです！
* gopher：言語仕様が容易なので引き継ぎが簡単、手間を惜しまずコード化する好きな言語で良い
* アンシブル：中央サーバ不要、SSHが不要、社内にPythonエンジニアが多い
* CloudFormation：新サービス対応が早く、本家なので問い合わせが簡単

#### コード化の一例紹介

* CloudFormationを素直に使うとテンプレートが肥大化する
* 頻出パターンをモジュール化
* YAMLをgopherに渡すとモジュールを集めて環境を作る
* 素直にAnsibleを使うとSSHキーの管理が大変
* 運用中のEC2は絶対に変更しないで、変更時は新規インスタンスを制作し引き継ぐ
* AMIは一切カスタマイズしないでプレイブックを設置

#### まとめ

* 運用者の祭典を加点方式に(事前計画とルールから解放する)
* 「今日もインフラ運用頑張っていきましょう！」「おー」

-----

### 【スクウェア・エニックス様ご登壇事例】『FINAL FANTASY XV POCKET EDITION』を支える AWS サーバーレス技術

* 6月1日(金) 16:00-16:40 旭光 3-P1-2-16

#### 堀内 要介 株式会社Luminous Productions プログラマー

* 今年関連会社として設立しスクエニから転籍
* スライドは後日公開予定
* ゲームは2月9日に公開、全世界150カ国で300万ダウンロード
* トレイラームービー(なんだかPS版FFのような絵)
* 基本的に一人用REGだけど、オンライン処理が必要になったのは「アプリ内課金のレシート対応が必要」(1アプリで体験版から章ごとの課金にも対応)
* これだけなので少人数短期間で開発したい
* サーバレスで安くしたい！
* 社内サポートセンターようツールはEC2等利用
* ユーザ向けにはAPI Gateway、Lambda、DynamoDBを利用
* API GatewayからLambda呼び出し時は、Lambdaのエイリアスでの指定がオススメ、API Gateway初期同時実行数は10000
* Lambda初期同時実行数は1000(実績で上げられる)
* DynamoDBがスループットが性能を決める、Point in Time Recoveryで35日以内のデータを復旧できるのでバックアップの手間すら減らす
* LambdaからKinesisへログを送る
* 事故や障害なし、お客様の問い合わせもなし
* AWSから負荷テストのサポートを受けることが出来た

#### 重国 和宏 株式会社スクウェア・エニックス テクノロジー推進部 リードオンラインエンジニア

* DynamoDBのチューニング：リリース時だけ手動で上げ以外はCapacity Auto Scalingにお任せ
* トランザクションなしでアプリケーション開発：一貫性が保たれなくても問題無いか、TLA+でロジックをチェック
* TLA+でチェック・仕様を複数人でチェック・サーバ実装をチェック、三段チェックでトランザクション無しを克服
* DynamoDBのバックアップ：開発中に新しいサービスが開発されどんどん簡単に、今ならPoint in Time Recoveryを考慮しよう
* 従来の差分ログのS3保存は継続して二重バックアップ
* アプリケーション障害によってはPITRだけで十分(1秒未満の粒度で巻き戻しは出来ないし、プログラムによる誤書き込みを救うのも若干難がある)
* LambdaはNode.JS v6.10で制作、Lambdaの実行時間の大半はレシート検証サーバからの応答待ち(待ち時間も料金を払っているかそれでも安い)
* またLambdaは負荷テストのクライアントとしても使える
* API GatewayからLambdaデプロイ時はパラメータが記録されないので外部へ記録する
* Lambdaは便利だけどサービス同士の結合は手動で確認、このままだと大規模開発時にコストが増大しそう、小規模でもうまく管理する方法が今後の課題
* サーバーレスアプリ開発には課題があるが、小規模なアプリケーションであれば問題になりずらい

-----

### 【ミクシィXFLAG スタジオ様ご登壇事例】モンスターストライクを支えるデータ分析基盤とリアルタイム集計システム

* 6月1日(金) 17:00-17:40 旭光 3-P1-2-17
* 生島 光
株式会社ミクシィXFLAG スタジオ モンスト事業本部 ゲーム運営部 解析グループ 解析チームデータエンジニア

### 本編

* 世界利用者数4600万人
* 友達や家族とわいわい騒ぐエンターテイメントの開発
* データ分析専門のチームが5人
* また開発者200人がログデータにアクセス
* 1日のデータは2TこれをS3に保存し現状1ペタ
* DBは8台繋ぎ48テラバイトのクラスターとして使用
* データ分析基盤4年間の歴史を紹介
* 後半は準リアルタイム実績の照会

#### データ分析基盤4年間の歴史

* モンスト稼働時はログをそのままS3に保存しアドホックに解析
* EMRの起動が遅い：MSCKリペアテーブルの構築に30分かかる、ハイブメタストアの永続化し5分ほどに短縮
* Hiveが遅い：バッチ処理に15時間かかる、全てのデータをORCに変換、その他定番の最適化で
* アプリケーションログの解析：ダイナミックパーティションでログ種別を分ける(ログイン・ゲーム実行など)
* Hiveのバッチが15時間から9時間に
* バッチ処理のタスク管理やリトライが課題に、ジョブ管理ツール(ルイージやエアフローが有名だけど今回は内製した)でタスクを最適な場所に置く
* データ活用の課題：エンジニアしかデータに触れないのでBIツール(対話的にはセペリン、ダッシュボードはメタベース)を導入
* それでもクエリが複雑で一部の人しか書けない、例えばソロプレイかマルチプレイかの判定にゲームの内部仕様を知らないと抽出できない(同日時間においてゲームの部屋主ID利用が自分一人か複数PLか頑張って検索)
→IsMultiカラムを作成(名前をわかりやすいように)
* ディメンジョナルモデルに40種類ほど追加し誰でも利用できるように
* 多くの人が使うとデータ破損に気がつかない場合がある、間違ったデータで経営判断する可能性が
* 事前検証・事後検証(異なるデータを比較)でデータ欠損を確認
* 例えば「ユーザDBの最終ログイン時刻」と「ログログの最終実行時刻」が一致しているか

#### 準リアルタイム集計

* 31(アイス)ゲットキャンペーン：現在のクーポンの、DynamoDBの条件付きカウントアップを計測、秒間2.5万クエリを処理
* モンストビンゴ：生番組中にビンゴを行いリアルタイムでビンゴを検出、Redshiftが頑張った
* ファイトリーグのグランドカップ：3時間の短時間大会でリアルタイム順位商事、kinesisからRedshiftにデータを投げる、実装期間半日

#### 将来の課題

* 全サービスを横断して検索出来る仕組みが欲しい
* 利用者毎のデータガバナンスの策定
* 機械学習でデータ分析したい

-----

### アンケート用メモ

* 飛飛天でのレシーバーを使ったセッションは選択したチャンネル番号が正しいか確かめるため、BGMとしてチャンネル番号(と出来れば次回のセッション名)をアナウンスして欲しい(そもそも開始前のレシーバーチェックのため、会場スピーカー＋3チャンネルでBGMを分けて欲しい)
* あと「飛天 2-H1-3-14」のセッション開始前の壇上打ち合わせがレシーバー3チャンネルに流れていましたが問題無いのでしょうか。
